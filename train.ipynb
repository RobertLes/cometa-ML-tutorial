{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code summary\n",
    "This notebook will guide a very simple example of how to train a classifier (aka \"jet-tagger\") with pytorch using th ATLAS top-tagging dataset at https://opendata.cern.ch/record/80030.\n",
    "\n",
    "To be able to run this tutorial within a reasonable time, we will develop just a tagger on the 16 high-level features stored. Constituent level taggers can be easily done using the below recipes, but the training time can easily go into the range of days. For similar time reasons, we will only run on one file of 1 million jets, as opposed to the full dataset (which is several hundred GB in total size to download locally as well).\n",
    "\n",
    "We will assume you are familiar with the inspect_inputs.ipynb notebook already and will skip the explanantion on the file format and how to access the data.\n",
    "\n",
    "Much of the code below is more elaborate then is needed for a simple tutorial, but this is so that it can provide a useful copy-and-paste template for your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessing the data\n",
    "Exactly as before, lets download an input file to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "if not(os.path.isfile(\"train_nominal_000.h5\")):\n",
    "    if sys.platform==\"darwin\": #MAC OSX\n",
    "        !curl https://opendata.cern.ch/record/80030/files/assets/atlas/datascience/CERN-EP-2024-159/train_nominal_000.h5.gz --output train_nominal_000.h5.gz\n",
    "        !curl https://opendata.cern.ch/record/80030/files/assets/atlas/datascience/CERN-EP-2024-159/test_nominal_000.h5.gz --output test_nominal_000.h5.gz\n",
    "    elif sys.platform == \"linux\" or sys.platform == \"linux2\":\n",
    "        !wget https://opendata.cern.ch/record/80030/files/assets/atlas/datascience/CERN-EP-2024-159/train_nominal_000.h5.gz\n",
    "        !wget https://opendata.cern.ch/record/80030/files/assets/atlas/datascience/CERN-EP-2024-159/test_nominal_000.h5.gz\n",
    "    !gunzip -f train_nominal_000.h5.gz\n",
    "    !gunzip -f test_nominal_000.h5.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's import some packages we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the inputs for training\n",
    "\n",
    "90% of the hard work of running any machine-learning algorithm is setting up your data in the right form.\n",
    "\n",
    "To faciliate reading the data very efficiently we will use the pytorch `DataLoader` class to do most of this heavy lifting. This is one of the only things you would need to adapt if you want to use this code for other NN training. For each dataset you need to define a new class which inherits from pytorch `Dataset` which specifies how to access your data. It needs a `__init__` method to do any preamble works, a  `__getitem__` method which specifies how to access a single data sample, and `__len__` method to specify how to figure out the batch size correctly.\n",
    "\n",
    "After this the pytorch dataloader will handle the rest!\n",
    "\n",
    "For this case we will use the `__init__` function to opent the necessary file, and read the HDF5 \"Dataset\" objects. We also will be mentally pro-active and feed the code an optional transform object to pre-process the data. The `__getitem__` just then simply calls the specific entry of the HDF5 \"Dataset\" and return a pytorch `torch.tensor` object, which functions almost identical to a numpy array (this isn't expliclity needed, but convenient for us as we will just use tensors from here on). \n",
    "\n",
    "The HDF5+Dataloader combination is quite memory efficienct and will only load into memory the batch of data at a time, as opposed to the whole thing in memmory. The dataset has one complexitiy in that only the training sample has training weights, so we will just return a `1` for testing events which lack this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATLASH5HighLevelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, transform=True):\n",
    "        super(ATLASH5HighLevelDataset, self).__init__()\n",
    "        \n",
    "        #load the file and specify a data object for later convenience\n",
    "        h5_file = h5py.File(file_path , 'r')\n",
    "        self.data=torch.tensor([])\n",
    "    \n",
    "        #Get in input variables\n",
    "        self.C2=h5_file['fjet_C2']\n",
    "        self.D2=h5_file['fjet_D2']\n",
    "        self.ECF1=h5_file['fjet_ECF1']\n",
    "        self.ECF2=h5_file['fjet_ECF2']\n",
    "        self.ECF3=h5_file['fjet_ECF3']\n",
    "        self.L2=h5_file['fjet_L2']\n",
    "        self.L3=h5_file['fjet_L3']\n",
    "        self.Qw=h5_file['fjet_Qw']\n",
    "        self.Split12=h5_file['fjet_Split12']\n",
    "        self.Split23=h5_file['fjet_Split23']\n",
    "        self.Tau1_wta=h5_file['fjet_Tau1_wta']\n",
    "        self.Tau2_wta=h5_file['fjet_Tau2_wta']\n",
    "        self.Tau3_wta=h5_file['fjet_Tau3_wta']\n",
    "        self.Tau4_wta=h5_file['fjet_Tau4_wta']\n",
    "        self.ThrustMaj=h5_file['fjet_ThrustMaj']\n",
    "        self.m=h5_file['fjet_m']\n",
    "        self.pt = h5_file['fjet_pt']\n",
    "        self.labels = h5_file['labels']\n",
    "        \n",
    "        #pre-process the inputs\n",
    "        if transform:\n",
    "            self.C2=self.transform(self.C2)\n",
    "            self.D2=self.transform(self.D2)\n",
    "            self.ECF1=self.transform(self.ECF1)\n",
    "            self.ECF2=self.transform(self.ECF2)\n",
    "            self.ECF3=self.transform(self.ECF3)\n",
    "            self.L2=self.transform(self.L2)\n",
    "            self.L3=self.transform(self.L3)\n",
    "            self.Qw=self.transform(self.Qw)\n",
    "            self.Split12=self.transform(self.Split12)\n",
    "            self.Split23=self.transform(self.Split23)\n",
    "            self.Tau1_wta=self.transform(self.Tau1_wta)\n",
    "            self.Tau2_wta=self.transform(self.Tau2_wta)\n",
    "            self.Tau3_wta=self.transform(self.Tau3_wta)\n",
    "            self.Tau4_wta=self.transform(self.Tau4_wta)\n",
    "            self.ThrustMaj=self.transform(self.ThrustMaj)\n",
    "            self.m=self.transform(self.m)\n",
    "        \n",
    "        #If has training weights access those too\n",
    "        if \"training_weights\" in h5_file:\n",
    "            self.hasWeights=True\n",
    "            self.weights = h5_file['training_weights']\n",
    "        else:\n",
    "            self.hasWeights=False\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #Make the array of high-level features\n",
    "        self.data=torch.tensor([self.D2[index],self.C2[index],self.ECF1[index],self.ECF2[index],self.ECF3[index],self.L2[index],self.L3[index],self.Qw[index],self.Split12[index],self.Split23[index],self.Tau1_wta[index],self.Tau2_wta[index],self.Tau3_wta[index],self.Tau4_wta[index],self.ThrustMaj[index],self.m[index]])\n",
    "    \n",
    "        #Finally return [inputs, labels, and weight]\n",
    "        if self.hasWeights:\n",
    "            return self.data,torch.tensor(self.labels[index],dtype=torch.int64),torch.tensor(self.weights[index])\n",
    "        else:\n",
    "            return self.data,torch.tensor(self.labels[index],dtype=torch.int64),torch.tensor(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As hinted above, you may want to do some pre-processing of your data. If you want to do this on-the-fly, you can easily add a new method to your class and call it.\n",
    "\n",
    "Usually neural nets perform better when the input variables are on the same scale, which ours are not currently (e.x. eta is ~1 but pt from 1e3-1e6 MeV). So we will apply a little pre-processing where we scale the distribution to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(self,data):\n",
    "    \n",
    "    #Calculate some metrics from subsample of total\n",
    "    vals=[]\n",
    "    Njets=np.max([1000,data.len()])\n",
    "    for jet in range(Njets): vals.append(data[jet])\n",
    "    maxval=np.max(vals)\n",
    "    minval=np.min(vals)\n",
    "    return (data-minval)/(maxval-minval)\n",
    "\n",
    "setattr(ATLASH5HighLevelDataset, 'transform', transform) #can setattr or just include in original class definiton above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now lets make a little script to load up any input files into our custom pytorch `Dataset` and into a `DataLoader`. Note this script is more complicated then it needs to be for just single file inputs like ours, but it generalizes to when you may want to run over many inputs\n",
    "\n",
    "First we just get the list of input files, then we just feed them into a seperate `ATLASH5HighLevelDataset` for each file. Then we can use `ConcatDataset` to easily append these all into one dataset. (I find this more memory efficient then having one Dataset try to load in multiple files at once).\n",
    "\n",
    "Then we just feed this `Dataset` into a `DataLoader`. Here we tell the loader the batch size and to shuffle the data and it will automate the rest of the work! This might have seemed pretty convoluted but using these pytorch classes is simpler then trying to automate many of these procedure efficiently yourself. (Also if in other projects you need to split the training/testing sample yourself you can use `torch.utils.data.random_split` on the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ATLAS_inputs(directory,batch_size=2**8,transform=True):\n",
    "    \n",
    "    #Get list of input files\n",
    "    training_list=[]\n",
    "    testing_list=[]\n",
    "    for file in sorted(os.listdir(directory)):\n",
    "        if not \".h5\" in file: continue\n",
    "        if \"train\" in file:\n",
    "            print(\"Using file %s for training\"%(directory+\"/\"+file))\n",
    "            training_list.append(directory+\"/\"+file)\n",
    "        elif \"test\" in file:\n",
    "            print(\"Using file %s for testing\"%(directory+\"/\"+file))\n",
    "            testing_list.append(directory+\"/\"+file)\n",
    "    \n",
    "    #Get the datasets via our custom torch.utils.data.Dataset class\n",
    "    training_DSlist=[]\n",
    "    testing_DSlist=[]\n",
    "    for file in training_list: training_DSlist.append(ATLASH5HighLevelDataset(file,transform=transform))\n",
    "    for file in testing_list: testing_DSlist.append(ATLASH5HighLevelDataset(file,transform=transform))\n",
    "    \n",
    "    #concat them into one object\n",
    "    training_data = ConcatDataset(training_DSlist)\n",
    "    testing_data = ConcatDataset(testing_DSlist)\n",
    "    \n",
    "    #load them into torch dataloaders \n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(testing_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    #return\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call this function and load in the info! We'll include some walltime clocking as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file .//test_nominal_000.h5 for testing\n",
      "Using file .//train_nominal_000.h5 for training\n",
      "Took 1.108e+01 seconds to run data loading\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get dataloaders, function in utils.py\n",
    "starttime=time.time()\n",
    "train_dataloader,test_dataloader=get_ATLAS_inputs(\"./\",batch_size=2**8)\n",
    "print(\"Took %.3e seconds to run data loading\\n\"%((time.time()-starttime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can see the benefit of our labour as we can enumerate over the datasets now very quickly. Let's look at just the first entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: torch.Size([256, 16]), torch.float32\n",
      "Shape of y: torch.Size([256]) torch.int64\n",
      "Shape of z: torch.Size([256]) torch.float32\n",
      "tensor([[0.1698, 0.1614, 0.6255,  ..., 0.0370, 0.7191, 0.0554],\n",
      "        [0.0658, 0.2359, 0.0791,  ..., 0.1714, 0.3843, 0.0123],\n",
      "        [0.0464, 0.4339, 0.0743,  ..., 0.3038, 0.7345, 0.0591],\n",
      "        ...,\n",
      "        [0.0867, 0.4473, 0.0496,  ..., 0.1885, 0.8424, 0.0278],\n",
      "        [0.0412, 0.0591, 0.6021,  ..., 0.0240, 0.4454, 0.0398],\n",
      "        [0.0355, 0.5369, 0.3237,  ..., 0.3531, 0.7445, 0.3365]]) tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1]) tensor([2.0107, 0.2266, 0.2886, 1.0000, 0.0970, 0.1037, 1.0820, 2.7716, 1.0000,\n",
      "        1.0000, 1.0000, 0.0970, 1.9603, 1.0000, 1.1591, 1.0000, 1.0000, 0.1037,\n",
      "        0.5515, 1.0000, 0.1181, 0.6192, 1.0000, 0.2266, 1.0000, 0.1775, 1.0000,\n",
      "        1.0000, 0.0970, 0.0970, 0.5010, 0.2886, 1.9597, 1.0000, 1.0000, 1.0000,\n",
      "        1.1606, 1.0000, 1.0000, 1.0000, 1.0161, 1.0000, 1.0000, 1.0000, 1.6899,\n",
      "        0.1419, 1.4298, 0.1775, 1.0000, 1.2953, 1.0000, 1.1621, 1.4339, 1.0000,\n",
      "        0.0970, 1.0000, 0.1037, 0.1037, 1.0000, 1.0000, 1.0000, 0.6192, 0.6555,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 2.3239, 2.0646, 1.0000, 1.0000, 0.0970,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.6555, 2.0015, 1.0000, 1.0000,\n",
      "        0.7207, 2.0709, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.6141,\n",
      "        1.9126, 0.0970, 1.0000, 0.3599, 1.0000, 1.0000, 1.6458, 1.0000, 1.0000,\n",
      "        1.0000, 1.2387, 0.1037, 1.0000, 1.2588, 1.5257, 1.0000, 0.6202, 1.0000,\n",
      "        1.0000, 2.0128, 1.0000, 1.0000, 0.7601, 0.6202, 1.0000, 0.7601, 1.0000,\n",
      "        1.0000, 1.5604, 1.1135, 1.0000, 0.0970, 1.0000, 0.3599, 0.1037, 1.0000,\n",
      "        0.1419, 1.0000, 1.0000, 1.0000, 0.0970, 1.0000, 1.6912, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.2953, 1.0000, 1.2256, 0.4343, 1.9562, 1.0000, 1.0000,\n",
      "        2.0412, 0.1775, 2.9010, 0.2266, 1.0000, 1.2588, 1.0000, 1.0000, 1.3061,\n",
      "        1.0000, 1.0000, 1.9597, 0.1037, 1.0000, 1.6331, 0.7601, 1.0000, 1.4774,\n",
      "        1.2953, 1.3069, 1.4740, 1.0000, 1.0000, 1.2870, 1.0000, 1.0000, 1.3484,\n",
      "        0.1419, 0.2266, 0.2266, 1.3233, 1.0000, 1.0000, 0.1419, 1.0000, 1.1716,\n",
      "        1.5526, 1.0000, 1.0000, 0.1775, 0.1775, 0.3599, 1.0000, 1.7107, 1.2588,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.6086,\n",
      "        1.0000, 0.6077, 0.6086, 0.1037, 1.0000, 1.0000, 1.5526, 0.1037, 0.0970,\n",
      "        1.3804, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.6016, 1.0000,\n",
      "        1.3275, 1.0000, 1.1961, 1.0000, 1.6331, 0.1419, 0.1181, 1.9562, 1.0000,\n",
      "        0.9411, 0.9246, 1.0000, 1.0000, 0.9353, 0.6202, 1.0000, 1.0000, 1.0000,\n",
      "        1.2333, 1.4936, 1.0000, 0.9961, 0.8484, 1.0000, 1.0000, 1.0000, 0.6077,\n",
      "        1.0000, 1.3140, 1.3908, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 2.0646,\n",
      "        0.0970, 0.1037, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "#Quick debug on input shape\n",
    "for x, y, z in train_dataloader:\n",
    "    print(f\"Shape of x: {x.shape}, {x.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    print(f\"Shape of z: {z.shape} {z.dtype}\")\n",
    "    print(x,y,z)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can each call returns a triple of number, which is what we specified in our `__getitem__` class function. We had defined it to return \\[inputs, truth label, weight\\]. Looking at the dimnesions you can see one pass of the data-loader loads up an array of dimension \\[256, \\], where this 256 is the batch dimension, aka the number of jets. So every pass of the data-loader will load up a new batch of 256 jets. \n",
    "\n",
    "Also note you can see from `x` value you can make these returns as complex in dimension as you want. These `torch.tensor` objects can also be sliced/indexed like numpy arrays for convenience and usually have the same class methods available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Neural net model\n",
    "\n",
    "Okay now onto defining the model we would like to fit. This is the other part which involves user input/design, but is much easier then you would expect. Let's make just a simple dense neural network 4 layers deep, with 512 hidden node per layer, and ReLU activation functions.\n",
    "\n",
    "A pytorch model will inherit from `torch.nn.Module`, it just needs the usually intializer and a `forward` function. Almost everything you would want is already available in the `torch.nn` package, so you can look at the classes available there. The most generic way to define a model is to make an object for each layer and activation, then in the forward pass to just call these classes in the order desired.\n",
    "\n",
    "The one thing we will note here is that the final output layer is actually 2 nodes, while we are just planning to do binary classification. You can of course phrase the problem with just one output node, but we will have the tutorial with 2 nodes as it generalizes to when you may want to do multiple classification problems (say Higgs vs W vs top vs QCD tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNetwork(nn.Module):\n",
    "    def __init__(self, Ninputs): #Here we decide to feed the class also an Ninputs variation to make it robust to input list changes\n",
    "        super().__init__()    \n",
    "\n",
    "        #Define the actual layers and activations fucntions\n",
    "        self.fc1= nn.Linear(Ninputs, 512)\n",
    "        self.act1=nn.ReLU()\n",
    "        self.fc2= nn.Linear(512, 512)\n",
    "        self.act2=nn.ReLU()\n",
    "        self.fc3= nn.Linear(512, 512)\n",
    "        self.act3=nn.ReLU()\n",
    "        self.fc4= nn.Linear(512, 2)\n",
    "        self.act4=nn.Sigmoid() # We won't apply this since done in loss function\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Put these layers together in sequence\n",
    "        f1=self.act1(self.fc1(x))\n",
    "        f2=self.act2(self.fc2(f1))\n",
    "        f3=self.act3(self.fc3(f2))\n",
    "        \n",
    "        #We will return just the last layer values, no activations here\n",
    "        logits = self.fc4(f3)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That wasn't too bad, now let's call the model. We'll first get the dimension size and feed it to the model.\n",
    "\n",
    "I'll also show you a quick little feature of pytorch, which is how to put things on GPU (if it's available). All you need to do is have the device name, usually something like `cuda:0` and then for whatever you want to load onto the GPU memory, like the model or the input `torch.tensor`, you just call `.to(device)` method on it to send it there. As \"simple\" as that. Probably you will just have `device=\"cpu\"` here which is fine for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device \"cpu\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get size of the input\n",
    "Ndim = x.size(dim=1)\n",
    "\n",
    "#Get whether a GPU is available\n",
    "device = ( \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device \\\"{device}\\\"\\n\")\n",
    "\n",
    "#Now make the model\n",
    "model = DNNetwork(Ndim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now let's do a bit of model visualization, we can just print the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNNetwork(\n",
      "  (fc1): Linear(in_features=16, out_features=512, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (act3): ReLU()\n",
      "  (fc4): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (act4): LogSoftmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm maybe not the most useful, but still helpful. There is also the `torchinfo` package which we inlcuded as a dependency in this tutorial, which offers a bit more helpful breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape     Output Shape    Param #         Param %         Mult-Adds       Trainable\n",
       "==================================================================================================================================\n",
       "DNNetwork                                [256, 16]       [256, 2]        --                   --         --              True\n",
       "├─Linear: 1-1                            [256, 16]       [256, 512]      8,704             1.63%         2,228,224       True\n",
       "├─ReLU: 1-2                              [256, 512]      [256, 512]      --                   --         --              --\n",
       "├─Linear: 1-3                            [256, 512]      [256, 512]      262,656          49.09%         67,239,936      True\n",
       "├─ReLU: 1-4                              [256, 512]      [256, 512]      --                   --         --              --\n",
       "├─Linear: 1-5                            [256, 512]      [256, 512]      262,656          49.09%         67,239,936      True\n",
       "├─ReLU: 1-6                              [256, 512]      [256, 512]      --                   --         --              --\n",
       "├─Linear: 1-7                            [256, 512]      [256, 2]        1,026             0.19%         262,656         True\n",
       "==================================================================================================================================\n",
       "Total params: 535,042\n",
       "Trainable params: 535,042\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 136.97\n",
       "==================================================================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 3.15\n",
       "Params size (MB): 2.14\n",
       "Estimated Total Size (MB): 5.31\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,input_size=x.size(),col_names=[\"input_size\", \"output_size\", \"num_params\",\"params_percent\",\"mult_adds\",\"trainable\"],col_width=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now that we have the inputs, and defined the model, we can finalize the problem definition by providing the loss function and optimizer procedure for that function.\n",
    "\n",
    "Here we will use cross entropy as our loss function, which is a common choice for such classification problems. One sneaky thing is that the `torch.nn.CrossEntropyLoss` class expects the \"logits\" of the network and applies a soft-max function on the inputs internally. So this is why we didn't apply this in the final layer of the network ouput. This choice from the developers is due to it being numerically faster/stabler, and you should keep an eye out for similar tricks for other loss functions in pytorch.\n",
    "\n",
    "We also will use Stochastic Gradient Descent as our optimizer. Adam is another (more common) choice. There are some options to the optimizer such as the learning rate, which are hyperparamaters, and should be optimized themselves for your problem. We'll just use some reasonable guesses for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction='none') #expects raw score\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.0, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model training\n",
    "\n",
    "Okay the rest from here on out is pretty standard machine-learning approaches, and will be common to almost any problem.\n",
    "\n",
    "We'll first define a function for each training loop, just to modularize the code.\n",
    "\n",
    "We'll first set the model into \"training mode\", which just does some behind the scenes things for special cases like dropout and normalization layers. Then we start looping over the batches (note we also load into the device if using a GPU). Once the loop is done we will have gone over all the training data, aka an epoch.\n",
    "\n",
    "Then it's as simple as computing the loss and calling the backpropogation to update the neural net weights. But let's break this down. \n",
    "\n",
    "First we calculate the prediction of the model, just by calling it on the input tensor `X`. This calls the `forward` method we had defined earlier in the model class. This will be computed automatically across the batch so our prediction will be of dimension \\[batch, 2\\] since we have 2 ouput nodes. Then we provide the prediction and the true labels `y` into out loss fucntion. Since we have per-jet weights `w`, we will also do a quick weighted average of the loss function. The loss function is now one number over the batch\n",
    "\n",
    "Now to actually update the model parameters, we will first call optmizer `.zero_grad()` to remind pytorch to set all the gradients to zero (you might not want to do this for some networks like RNNs). Then on the loss fucntion you call `.backward()`, this does all the internal magic of calculating the gradients of the model paramaters! Then you let the optimizer do it's magic with `.step()` to actually update the model parameters based on their gradients\n",
    "\n",
    "It's as easy as that!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, loss_train):\n",
    "    #set to train mode\n",
    "    model.train()\n",
    "    \n",
    "    #Loop over batches\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y, w) in enumerate(dataloader):\n",
    "        dev=device\n",
    "        X, y, w = X.to(dev), y.to(dev), w.to(dev)\n",
    "      \n",
    "        # Compute loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss = (loss * w / w.sum()).sum() #weighted average of the loss function\n",
    "      \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Print some status\n",
    "        if batch % 100 == 0:\n",
    "            lossval, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Training loss: {lossval:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "      \n",
    "    loss_train.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define a function for simplicity a function to evalaute the network performance on the training data. \n",
    "\n",
    "It is very similar to the train function but we don't update the gradients. For this we set the model in eval mode, to handle special layers like dropout and normalization layers, and also scope everything in `torch.no_grad()`, which just tells pytorch to not worry about graident layers.\n",
    "\n",
    "Then we again loop over the dataset, calculate the prediction, and find the loss function. We'll store an \"accuracy metric\" which is just the prediction of the networks largest node for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, loss_test, acc_test):\n",
    "    #Set to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    #Some info for averaging across the samples\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    avgloss, acc = 0, 0\n",
    "    \n",
    "    #Loop over batches\n",
    "    with torch.no_grad():\n",
    "        for X, y, w in dataloader:\n",
    "            X, y, w = X.to(device), y.to(device), w.to(device)\n",
    "        \n",
    "            #compute loss\n",
    "            pred=model(X)\n",
    "            loss=loss_fn(pred, y)\n",
    "            avgloss += loss.sum().item()\n",
    "        \n",
    "            #compute accuracy\n",
    "            pred=torch.sigmoid(pred)\n",
    "            acc += (torch.argmax(pred, dim=1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    #save and print some info\n",
    "    avgloss /= num_samples\n",
    "    acc /= num_samples\n",
    "    loss_test.append(avgloss)\n",
    "    acc_test.append(acc)\n",
    "    print(f\"Testing Error: Accuracy: {(100*acc):>0.1f}%, Avg loss: {avgloss:>8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now let's run the training cycle. It's really as simple as looping multiple times over our `train()` and `test()` function multiple times. We'll also save the model whenever it improves with `torch.save(model.state_dict(), outputfile)`\n",
    "\n",
    "Usually network performance on the testing dataset will degrade eventually, as the network becomes over-trained on the training dataset and can't extrapolate to other datasets. So we will define an early stopping criteria where once the performance on the testing dataset doens't improve over 5 epochs to stop the training.\n",
    "\n",
    "Now run below the cell below, but note it will probably take ~10min for even this simple network and small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Training loss: 0.694435  [  256/100000]\n",
      "Training loss: 0.617320  [25856/100000]\n",
      "Training loss: 0.583033  [51456/100000]\n",
      "Training loss: 0.576701  [77056/100000]\n",
      "Testing Error: Accuracy: 74.5%, Avg loss: 0.543586\n",
      "Took 0.26 minutes to run\n",
      "Saving model since best loss\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Training loss: 0.563103  [  256/100000]\n",
      "Training loss: 0.480481  [25856/100000]\n",
      "Training loss: 0.440345  [51456/100000]\n",
      "Training loss: 0.535552  [77056/100000]\n",
      "Testing Error: Accuracy: 79.7%, Avg loss: 0.458199\n",
      "Took 0.25 minutes to run\n",
      "Saving model since best loss\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Training loss: 0.457995  [  256/100000]\n",
      "Training loss: 0.494843  [25856/100000]\n",
      "Training loss: 0.452918  [51456/100000]\n",
      "Training loss: 0.391571  [77056/100000]\n",
      "Testing Error: Accuracy: 81.9%, Avg loss: 0.411679\n",
      "Took 0.25 minutes to run\n",
      "Saving model since best loss\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Training loss: 0.484738  [  256/100000]\n",
      "Training loss: 0.515112  [25856/100000]\n",
      "Training loss: 0.404392  [51456/100000]\n",
      "Training loss: 0.377400  [77056/100000]\n",
      "Testing Error: Accuracy: 80.6%, Avg loss: 0.428586\n",
      "Took 0.27 minutes to run\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Training loss: 0.462180  [  256/100000]\n",
      "Training loss: 0.512654  [25856/100000]\n",
      "Training loss: 0.381616  [51456/100000]\n",
      "Training loss: 0.382130  [77056/100000]\n",
      "Testing Error: Accuracy: 82.8%, Avg loss: 0.386669\n",
      "Took 0.25 minutes to run\n",
      "Saving model since best loss\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Training loss: 0.412634  [  256/100000]\n",
      "Training loss: 0.407643  [25856/100000]\n",
      "Training loss: 0.353991  [51456/100000]\n",
      "Training loss: 0.481727  [77056/100000]\n",
      "Testing Error: Accuracy: 83.7%, Avg loss: 0.380667\n",
      "Took 0.26 minutes to run\n",
      "Saving model since best loss\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Training loss: 0.369412  [  256/100000]\n",
      "Training loss: 0.464000  [25856/100000]\n",
      "Training loss: 0.485117  [51456/100000]\n",
      "Training loss: 0.361483  [77056/100000]\n",
      "Testing Error: Accuracy: 82.7%, Avg loss: 0.394138\n",
      "Took 0.25 minutes to run\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Training loss: 0.400554  [  256/100000]\n",
      "Training loss: 0.446476  [25856/100000]\n",
      "Training loss: 0.516492  [51456/100000]\n",
      "Training loss: 0.351596  [77056/100000]\n",
      "Testing Error: Accuracy: 83.7%, Avg loss: 0.376758\n",
      "Took 0.25 minutes to run\n",
      "Saving model since best loss\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Training loss: 0.365122  [  256/100000]\n",
      "Training loss: 0.395082  [25856/100000]\n",
      "Training loss: 0.357213  [51456/100000]\n",
      "Training loss: 0.396263  [77056/100000]\n",
      "Testing Error: Accuracy: 83.8%, Avg loss: 0.374193\n",
      "Took 0.25 minutes to run\n",
      "Saving model since best loss\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Training loss: 0.440857  [  256/100000]\n",
      "Training loss: 0.368395  [25856/100000]\n",
      "Training loss: 0.351951  [51456/100000]\n",
      "Training loss: 0.513684  [77056/100000]\n",
      "Testing Error: Accuracy: 82.4%, Avg loss: 0.393069\n",
      "Took 0.25 minutes to run\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Training loss: 0.386869  [  256/100000]\n",
      "Training loss: 0.482395  [25856/100000]\n",
      "Training loss: 0.396053  [51456/100000]\n",
      "Training loss: 0.428569  [77056/100000]\n",
      "Testing Error: Accuracy: 83.0%, Avg loss: 0.385070\n",
      "Took 0.26 minutes to run\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Training loss: 0.359553  [  256/100000]\n",
      "Training loss: 0.387644  [25856/100000]\n",
      "Training loss: 0.448949  [51456/100000]\n",
      "Training loss: 0.348471  [77056/100000]\n",
      "Testing Error: Accuracy: 84.4%, Avg loss: 0.360525\n",
      "Took 0.25 minutes to run\n",
      "Saving model since best loss\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Training loss: 0.374246  [  256/100000]\n",
      "Training loss: 0.392101  [25856/100000]\n",
      "Training loss: 0.375891  [51456/100000]\n",
      "Training loss: 0.316355  [77056/100000]\n",
      "Testing Error: Accuracy: 83.9%, Avg loss: 0.368961\n",
      "Took 0.25 minutes to run\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Training loss: 0.424756  [  256/100000]\n",
      "Training loss: 0.401839  [25856/100000]\n",
      "Training loss: 0.399926  [51456/100000]\n",
      "Training loss: 0.418888  [77056/100000]\n",
      "Testing Error: Accuracy: 84.1%, Avg loss: 0.362744\n",
      "Took 0.25 minutes to run\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Training loss: 0.392258  [  256/100000]\n",
      "Training loss: 0.375057  [25856/100000]\n",
      "Training loss: 0.446494  [51456/100000]\n",
      "Training loss: 0.379143  [77056/100000]\n",
      "Testing Error: Accuracy: 83.2%, Avg loss: 0.379318\n",
      "Took 0.25 minutes to run\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Training loss: 0.422657  [  256/100000]\n",
      "Training loss: 0.448206  [25856/100000]\n",
      "Training loss: 0.507600  [51456/100000]\n",
      "Training loss: 0.405273  [77056/100000]\n",
      "Testing Error: Accuracy: 83.3%, Avg loss: 0.383219\n",
      "Took 0.25 minutes to run\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Training loss: 0.412330  [  256/100000]\n",
      "Training loss: 0.384492  [25856/100000]\n",
      "Training loss: 0.410243  [51456/100000]\n",
      "Training loss: 0.392401  [77056/100000]\n",
      "Testing Error: Accuracy: 83.9%, Avg loss: 0.369176\n",
      "Took 0.25 minutes to run\n",
      "Early stoping\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#run cycle\n",
    "\n",
    "#Some lists to fill each epoch\n",
    "loss_test=[]\n",
    "loss_train=[]\n",
    "acc_test=[]\n",
    "\n",
    "#For early stopping\n",
    "best_loss=1e6\n",
    "patience_counter=0\n",
    "patience=5\n",
    "\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    \n",
    "    #Run the training and testing loop\n",
    "    print(f\"\\nEpoch {t+1}\\n-------------------------------\")\n",
    "    starttime=time.time()\n",
    "    train(train_dataloader, model, loss_fn, optimizer, loss_train)\n",
    "    test(test_dataloader, model, loss_fn, loss_test, acc_test)\n",
    "    print(\"Took %.2f minutes to run\"%((time.time()-starttime)/60))\n",
    "\n",
    "    #Early stopping criteria. If the new loss the best save it. Otherwise, after some patience threshold stop the loop\n",
    "    if loss_test[-1]<best_loss:\n",
    "        best_loss=loss_test[-1]\n",
    "        patience_counter=0\n",
    "        print(f\"Saving model since best loss\")\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "    else:\n",
    "        patience_counter+=1\n",
    "        if patience_counter>=patience:\n",
    "            print(\"Early stoping\")\n",
    "            break\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You did it! You trained a nice little network with probably pretty reasonable performance. Let's also make a pretty standard validation plot showing the loss fucntion each epoch for the testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make some quick plots\n",
    "figure = plt.figure()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss_train)\n",
    "plt.plot(loss_test)\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.savefig(f\"loss.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CometaTutorial-venv",
   "language": "python",
   "name": "cometatutorial-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
